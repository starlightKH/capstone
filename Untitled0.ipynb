{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starlightKH/capstone/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T1wSk8WHBA0S"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (227, 13) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# 음성 파일 로드\u001b[39;00m\n\u001b[0;32m     18\u001b[0m speech_files \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(speech_dir, file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(speech_dir) \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m---> 19\u001b[0m speech_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray([extract_features(file) \u001b[39mfor\u001b[39;49;00m file \u001b[39min\u001b[39;49;00m speech_files])\n\u001b[0;32m     21\u001b[0m \u001b[39m# 노이즈 파일 로드\u001b[39;00m\n\u001b[0;32m     22\u001b[0m noise_files \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(noise_dir, file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(noise_dir) \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m\"\u001b[39m)]\n",
            "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (227, 13) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 음성 파일과 노이즈 파일이 들어있는 디렉토리 설정\n",
        "speech_dir = \"D:\\capstone 파일\\교통소음\\\\130.도시 소리 데이터\\\\01.데이터\\\\2.Validation\\원천데이터\\VS_1.교통소음.zip\\\\1.자동차\\\\3.차량주행음\"\n",
        "noise_dir = \"D:\\capstone 파일\\교통소음\\\\130.도시 소리 데이터\\\\01.데이터\\\\2.Validation\\원천데이터\\VS_1.교통소음.zip\\\\1.자동차\\\\1.차량경적\"\n",
        "\n",
        "# 음성 파일과 노이즈 파일 로드 및 특성 추출\n",
        "def extract_features(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    return mfccs\n",
        "\n",
        "# 음성 파일 로드\n",
        "speech_files = [os.path.join(speech_dir, file) for file in os.listdir(speech_dir) if file.endswith(\".wav\")]\n",
        "speech_data = np.array([extract_features(file) for file in speech_files])\n",
        "\n",
        "# 노이즈 파일 로드\n",
        "noise_files = [os.path.join(noise_dir, file) for file in os.listdir(noise_dir) if file.endswith(\".wav\")]\n",
        "noise_data = np.array([extract_features(file) for file in noise_files])\n",
        "\n",
        "# 레이블 생성 (음성: 0, 노이즈: 1)\n",
        "speech_labels = np.zeros(len(speech_data))\n",
        "noise_labels = np.ones(len(noise_data))\n",
        "\n",
        "# 데이터 및 레이블을 합치고 섞음\n",
        "X = np.concatenate([speech_data, noise_data], axis=0)\n",
        "y = np.concatenate([speech_labels, noise_labels], axis=0)\n",
        "\n",
        "# 데이터를 훈련 세트와 테스트 세트로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 생성\n",
        "model = models.Sequential()\n",
        "model.add(layers.Reshape((X.shape[1], X.shape[2], 1), input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM1R4OvHg/LL95M8KCIUmAq",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
